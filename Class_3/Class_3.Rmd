---
title: "Econometria I"
subtitle: "<br/> Regresi√≥n Lineal Simple"
author: "PhD.(C) Orlando Joaqui-Barandica"
institute: "Pontificia Universidad Javeriana de Cali"
date: "2023"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: 
      - default
      - rladies
      - rladies-fonts
      - fonts_mtheme.css
      - sidney.css
    includes:
      in_header: "mathjax-equation-numbers.html"
    seal: false  
    nature: 
      ratio: 16:9
      beforeInit: "macros.js"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include = FALSE}
library(knitr)                              # paquete que trae funciones utiles para R Markdown
library(tidyverse)                          # paquete que trae varios paquetes comunes en el tidyverse
library(datos)                              # paquete que viene con datos populares traducidos al espa√±ol :)
library(shiny)
# opciones predeterminadas
knitr::opts_chunk$set(echo = FALSE,         # FALSE: los bloques de c√≥digo NO se muestran
                      dpi = 300,            # asegura gr√°ficos de alta resoluci√≥n
                      warning = FALSE,      # los mensajes de advertencia NO se muestran
                      error = FALSE)        # los mensajes de error NO se muestran


options(htmltools.dir.version = FALSE)

library(xaringan)

```

class: inverse, left, bottom
background-image: url("img/fondo.jpg")
background-size: cover


# **`r rmarkdown::metadata$title`**
----

## **`r rmarkdown::metadata$subtitle`**

### `r rmarkdown::metadata$author`
### `r rmarkdown::metadata$date`

```{r xaringanExtra-share-again, echo=FALSE}
xaringanExtra::use_share_again()
```

```{r xaringanExtra-clipboard, echo=FALSE}
xaringanExtra::use_clipboard()
```

---
name: hola
class: inverse, middle, center

<img style="border-radius: 60%;" src="img/jave.jpg"
width="150px"
/>

# Pontificia Universidad Javeriana de Cali

--

## Programa de Econom√≠a
---




.pull-left[

<br><br><br><br><br>

```{r echo=FALSE, out.width = "110%" }
knitr::include_graphics("img/gif1.gif")
```
]

<br><br><br><br><br>


.pull-right[
# Orlando Joaqui-Barandica
### [www.joaquibarandica.com](https://www.joaquibarandica.com)
 *PhD.(C) in Industrial Engineering* 
 
 *MSc. Applied Economics*
 
 *BSc. Statistics*
]

---

name: menu
background-image: url("img/back2.jpg")
background-size: cover
class: left, middle, inverse

# Contenido

----


.pull-left[

### `r icon("dice-d6")` [Causalidad](#Causalidad)

### `r icon("database")` [Tipos de datos](#TipoDatos)

### `r icon("dice-d6")` [An√°lisis de regresi√≥n lineal](#LinealSimple)

### `r icon("sort-numeric-up")` [MCO](#MCO)

]


.pull-right[



### `r icon("upload")` [Propiedades algebraicas de los estimadores](#propiedades)

### `r icon("broom")` [Supuestos modelo cl√°sico de regresi√≥n lineal](#supuestos)


### `r icon("sort-numeric-up")` [Coef. de determinaci√≥n](#determinacion)

### `r icon("upload")` [Fuentes de variaci√≥n](#variacion)



]

---


name: Causalidad
class: inverse, center, middle

# `r icon("dice-d6")`
# Causalidad
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---

# Causalidad

.font120[.green[A pesar de que el an√°lisis de regresi√≥n tiene que ver con la dependencia de una variable respecto de otras variables, esto no implica causalidad necesariamente.]]

<br>
.pull-left[

> .font120[`Una relaci√≥n estad√≠stica, por m√°s fuerte y sugerente que sea, nunca podr√° establecer una conexi√≥n causal: nuestras ideas de causalidad deben provenir de estad√≠sticas externas y, en √∫ltimo t√©rmino, de una u otra teor√≠a `]

]

.pull-right[
.center[
<img src="https://media.giphy.com/media/l2Je34w7WkZ84f3os/giphy.gif" width="95%"/>
]


]

---

class: inverse, center, middle
background-image: url(https://media.giphy.com/media/VdKEHcPsjrlQv9Cv5n/giphy.gif)
background-size: cover


# Causalidad

<br>
<br>

## En un ejemplo de rendimiento del cultivo, no hay una raz√≥n estad√≠stica para suponer que la lluvia no depende del rendimiento del cultivo.


## Considerar que el rendimiento del cultivo depende de la lluvia (entre otras cosas) se debe a cuestiones no estad√≠sticas: el sentido com√∫n indica que la relaci√≥n no puede ser a la inversa, pues no es posible controlar la lluvia mediante el rendimiento del cultivo.

---


# Causalidad

> .font140[En la mayor√≠a de las pruebas de teor√≠as econ√≥micas, as√≠ como en la evaluaci√≥n de pol√≠ticas p√∫blicas, **el objetivo de los economistas** es inferir que una variable (por ejemplo, la educaci√≥n) .orange[**tiene un efecto causal**] sobre otra variable (por ejemplo, la productividad de los trabajadores).]

<br> 
> .font140[Encontrar simplemente una relaci√≥n entre dos o m√°s variables puede ser sugestivo, pero no concluyente, a menos que pueda establecerse causalidad.]

<br>

> .font140[El concepto **ceteris paribus** ‚Äî.orange[**"si todos los dem√°s factores relevantes permanecen constantes"**]‚Äî tiene un papel importante en el an√°lisis causal.]

---


# Causalidad


.font180[$$salario = f(educ, exper, capacitaci√≥n)$$]

.font120[.orange[En este ejemplo, interesa conocer el efecto de una semana m√°s de capacitaci√≥n sobre el salario, cuando los dem√°s componentes en particular Educ y Exper, permanecen constantes.]]

- .font130[Si se logran mantener constantes todos los dem√°s factores relevantes...]
- .font130[... y se encuentra una relaci√≥n entre **capacitaci√≥n laboral** y **salarios**]

--

.center[
### Puede concluirse que tal capacitaci√≥n tiene un efecto causal sobre la productividad de los trabajadores.
]

.font120[A pesar de que esto puede parecer bastante sencillo, aun ya en este nivel inicial debe ser claro que, .green[**salvo en casos muy especiales, no ser√° posible mantener, literalmente, todo lo dem√°s sin cambio.**]]


---

# Causalidad

.font120[La pregunta fundamental en la mayor parte de los estudios emp√≠ricos es: ]

<br>
.center[
## ¬øse han mantenido constantes suficientes factores para que se justifique la causalidad?
]

<br>

- .font130[En la mayor√≠a de los casos, las hip√≥tesis en las ciencias sociales son de car√°cter ceteris paribus, es decir, para estudiar una relaci√≥n entre dos variables todos los dem√°s factores relevantes deben mantenerse constantes.]

- .font130[En las ciencias sociales, dado el car√°cter no experimental de la mayor parte de los datos que suelen recolectarse, hallar relaciones causales no es una tarea f√°cil.]


---

class: center, middle

# Datos experimentales $\neq$ Datos no experimentales

.font200[üö©üö©üö©]

---

name: TipoDatos
class: inverse, center, middle

# `r icon("database")`
# Tipos de datos
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---


# Tipos de datos

.pull-left[
### Las bases de datos econ√≥micos pueden ser de diversos tipos. 

.font130[
>Aunque algunos m√©todos econom√©tricos pueden ser empleados, con alguna o ninguna peque√±a modificaci√≥n, para distintos tipos de bases de datos, las caracter√≠sticas especiales de algunas bases de datos deben ser tomadas en cuenta y aprovecharse.]
]

.pull-right[
<br>
<br>
<br>
<br>
* ###Datos de corte transversal
* ###Datos de serie de tiempo
* ###Combinaci√≥n de cortes transversales
]

---


name: LinealSimple
class: inverse, center, middle

# `r icon("database")`
# An√°lisis de regresi√≥n lineal
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]




---

# An√°lisis de regresi√≥n lineal

<br>

El objetivo del an√°lisis de regresi√≥n es el de construir una funci√≥n que aproxime de la mejor manera el comportamiento de una variable aletoaria $(Y)$ a trav√©s del conocimiento previo del valor de una variable explicativa $(X)$, mediante una expresi√≥n lineal como la siguiente:

<br>

.font180[$$Y = \beta_0 + \beta_1X$$]

<br>

> - Y: es llamada la variable de respuesta o dependiente
> - X: es llamada la variable predictora o independiente
> - $\beta_0$: es el intercepto de la linea con el eje $Y$
> - $\beta_1$: es la pendiente de la linea de regresi√≥n



---

class: center

## Este modelo supone una **asociaci√≥n lineal** entre las variables de estudio, por tanto antes de empezar, esta relaci√≥n debe ser valorada


.pull-left[

```{r, warning=FALSE, echo=FALSE, message=FALSE, fig.height=5}


plot(iris$Petal.Length,iris$Petal.Width, main="Gr√°fico de dispersi√≥n")


# cor(iris$Petal.Length,iris$Petal.Width)


```


Correlaci√≥n entre `Petal.Length` y `Petal.Width` 0.96


]



.pull-right[

```{r, warning=FALSE, echo=FALSE, message=FALSE, fig.height=6.5}

library(ggcorrplot)

ggcorrplot(cor(iris[,-5]))

```



]


---

# An√°lisis de regresi√≥n lineal

<br>

El an√°lisis de regresi√≥n se relaciona en gran medida con la estimaci√≥n o predicci√≥n de la .orange[**media (de la poblaci√≥n) o valor promedio de la variable dependiente,**] con base en los valores conocidos o fijos de las variables explicativas.

<br>

> Las observaciones de la variable $Y$ (dependiente) se asumen aleatorias de una distribuci√≥n con media $E(Y|X=x)$. 

> Las desviaciones de las observaciones $y_i$ de la $E(Y|X=x)$ se tienen en cuenta adicionando un error aleatorio $u_i$ al siguiente modelo:

.font180[$$y_i = \beta_0 + \beta_1 x_i + u_i$$]


---

# Ejemplo

Estos datos se refieren a la poblaci√≥n total de 60 familias de una comunidad hipot√©tica, as√≠ como a su ingreso semanal $(X)$ y su gasto de consumo semanal $(Y)$, en d√≥lares. Las 60 familias se dividen en 10 grupos de ingresos (de 80 d√≥lares a 260); asimismo, aparecen los gastos semanales de cada familia de los diversos grupos. Por consiguiente, hay 10 valores fijos de $X$ y los correspondientes valores $Y$ para cada valor $X$; as√≠, hay 10 subpoblaciones $Y$.


.center[

<img src="img/ejm1.jpg" width="70%"/>

]


---

# Ejemplo

> En total hay 10 valores medios para las 10 subpoblaciones de Y. A estos valores medios se les llama valores esperados condicionales: $E(Y|X)$.

<br>

.pull-left[

Es importante distinguir entre los valores esperados condicionales y el valor esperado incondicional: $E(Y)$.


$$E(Y|X) \neq E(Y)$$



Si sumamos los consumos semanales de las 60 familias que forman la poblaci√≥n y dividimos este n√∫mero entre 60, obtendremos la cantidad de 121.20 d√≥lares (7272/60), que es el .orange[**valor de la media incondicional**], o esperada, del consumo semanal, $E(Y)$.

]

.pull-right[

.center[

<img src="https://media.giphy.com/media/hv53DaYcXWe3nRbR1A/giphy.gif" width="70%"/>

]

]


---

<br><br>

<img src="img/ejm2.jpg" width="90%"/>

### Esta figura muestra que para cada X (es decir, el nivel de ingresos) existe una poblaci√≥n de valores Y (consumo semanal) que se distribuyen alrededor de la media (condicional) de dichos valores Y.


---


# ¬øQu√© se puede decir sobre la relaci√≥n entre el consumo de una familia y un nivel determinado de ingresos?

<br>

Bajo el nivel de ingresos de $X_i$, el consumo de una familia en particular se agrupa alrededor del consumo promedio de todas las familias en ese nivel de $X_i$, es decir, alrededor de su esperanza condicional.

<br>

$$U = Y - E(Y|X)$$

o

$$Y = E(Y|X) + U$$

<br>

donde la desviaci√≥n $U$ es una variable aleatoria no observable que adopta valores positivos o negativos. T√©cnicamente, $U$ se conoce como .orange[**perturbaci√≥n estoc√°stica o t√©rmino de error estoc√°stico**]


---


# De esta ecuaci√≥n:

<br>

.font200[$$Y = E(Y|X) + U$$]


### Se puede decir que el gasto de una familia en particular, seg√∫n su nivel de ingreso, se expresa como la suma de dos componentes:


<br>

> - $E(Y|X)$ : que es simplemente la media del consumo de todas las familias con el mismo nivel de ingreso. Este componente se conoce como componente sistem√°tico, o determinista.


> - $U$ : que es el componente aleatorio, o no sistem√°tico.


---

# Enfoque Estadistico: Descomposici√≥n ortogonal

Sea $Y$ una variable aleatoria con segundo momento finito, es decir, $E(|Y|^2) < \infty$, y un conjunto de informaci√≥n D; entonces siempre podemos encontrar una descomposici√≥n de $Y$ como la siguiente:


.font180[$$Y = E(Y|D) + U$$]


d√≥nde el conjunto de informaci√≥n es $D : (X = x)$; por tanto $Y = E(Y|X) + U$ 

<br>

d√≥nde $E(Y | X)$ es una funci√≥n arbitraria.


---

# Enfoque Estadistico: Descomposici√≥n ortogonal


<br>

- $E(Y|X)$: Componente Sistem√°tico
- $U$: Componente no sistem√°tico

La existencia de dicha descomposici√≥n est√° garantizada siempre que $E(|Y|^2) < \infty$

<br>

### Ambos componentes de $Y$ deben satisfacer las siguientes propiedades:

- $E(U|X) = 0$
- $E(U^2|X) = Var(Y|X)< \infty$
- $E(U.E[Y|X])=0$



---


# Enfoque Estad√≠stico: Descomposici√≥n ortogonal


Con informaci√≥n de $X$ podemos descomponer la variable $Y$ en dos partes, pero no hay una .orange[**teor√≠a econ√≥mica**] detr√°s; por tanto no dice si hay relaciones de `causalidad` entre las variables.

<br>

.pull-left[

- Las variables X generaran parcialmente a Y.

- Y causa (o genera) las variables X.

- o bien, que hay alguna otra causa com√∫n (y quiz√° desconocida) que genera conjuntamente tanto a Y como a X.

]

.pull-right[

<img src="https://media.giphy.com/media/VmM6OYEREouic/giphy.gif" width="90%"/>

]

---

# Enfoque Econ√≥mico: Relaci√≥n "causal"


Se desea que la descomposici√≥n estad√≠stica sea reflejo de las relaciones te√≥ricas entre $X$ y $Y$.


### Ejemplo

**Y** (por ejemplo el .orange[**consumo**]) est√° generado por una funci√≥n de las variables **X** (por ejemplo una funci√≥n de la .orange[**renta**]) junto a otras causas distintas de la renta (**U**).


$$Y_n = h(X) + U_n$$
$$Y_n = h(1, X_1, X_2, ..., X_k) + U_n$$

* **Y**: .orange[**Variable End√≥gena.**] Se determina su valor o caracter√≠sticas a trav√©s del modelo 

* **X**: .orange[**Variables Ex√≥genas o de control**]. Vienen dadas de manera externa al modelo, se tiene la capacidad de "alterar" su valor para, a trav√©s del modelo, controlar $Y$.

* **U**: .orange[**Perturbaci√≥n.**] Efecto conjunto de otras variables o circunstancias que influyen en $Y$ y no observamos.


---


name: MCO
class: inverse, center, middle

# `r icon("database")`
# M√≠nimos cuadrados ordinarios
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---


# Modelo de regresi√≥n lineal

<br>
<br>

Modelo especial en el que la descomposici√≥n ortogonal

<br>


.font200[$$Y = E(Y|X) + U$$]

<br>


> Es tal que $E(Y|X)$ es una funci√≥n lineal de $x_n$

> $Var(Y|X)$ es constante.


---

# Modelo de regresi√≥n lineal

<br>

.pull-left[

> .font140[Hay .orange[tres supuestos generales] de un modelo econom√©trico que garantizan la existencia de una descomposici√≥n ortogonal como la del modelo cl√°sico de regresi√≥n lineal.]

]

.pull-right[

.center[

## - Linealidad

## - Exogeneidad estricta

## - Perturbaciones esf√©ricas

]

]

---



# MCO


.font140[En el an√°lisis de regresi√≥n lineal el objetivo es utilizar los datos para trazar una l√≠nea que represente mejor la relaci√≥n entre dos variables.]

.pull-left[

.center[

### Ya que se puede trazar m√°s de una recta que razonablemente se ajuste a la distribuci√≥n de los datos, es preferible utilizar el m√©todo de los **m√≠nimos cuadrados** que resulta en una sola y mejor l√≠nea de regresi√≥n *.orange[(Recta del mejor ajuste)]*.
]
]

.pull-right[
<br>
.center[
<img src="https://media.giphy.com/media/W0R3W6eC7lkuOZYCYU/giphy.gif" width="70%"/>
]
]

> **M√≠nimos Cuadrados Ordinarios (MCO):** El objetivo de este procedimiento es estimar los par√°metros tal que la suma de cuadrados (SC) de las diferencias entre las observaciones (valores reales) y la l√≠nea recta estimada sea m√≠nima (Min SCError).



---

# MCO

Si lo que interesa es minimizar la suma de cuadrados del error...


.center[
### ¬øQu√© es el error?
]

--

.font1800[$$\hat{e}_i = y_i - \hat{y}_i$$]

### Entonces, interesa...


.pull-left[
.center[
<img src="img/Imagen7.jpg" width="90%"/>
]
]

.pull-right[

<br>
$$SCE = \sum_{i=1}^n (y_i - \hat{y}_i)^2$$
]

---

# MCO

### Minimizar SCE:

$$SCE = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n (y_i - (\hat{\beta_0} + \hat{\beta_1}x_i))^2$$


$$Min SCE =  \frac{\partial SCE}{\partial \hat{\beta_j}}$$

--

### Ecuaciones normales:


$$\sum_{i=1}^n y_i = n \hat{\beta_0} + \hat{\beta_1} \sum_{i=1}^n x_i$$
$$\sum_{i=1}^n x_i y_i = \beta_0 \sum_{i=1}^n x_i + \hat{\beta_1} \sum_{i=1}^n x_i^2$$

---

# MCO

### Tarea: Demostrar. 

.font140[.orange[A partir de las ecuaciones normales llegar a:]]

<br>

$$\hat{\beta_0} = \bar{y} - \hat{\beta_1}\bar{x}$$

<br>
<br>


$$\begin{align}
\hat{\beta_1} & = & \frac{\sum_{i=1}^n x_i y_i - n \bar{x}\bar{y}}{\sum_{i=1}^n x_i^2 - n\bar{x}^2}   \nonumber \\
 & = & r \left( \frac{S_y}{S_x}\right)  \nonumber \\
 & = & \frac{cov(x,y)}{V(x)}
\end{align}$$


---

#MCO 

.font150[Una vez que se han determinado las estimaciones por MCO del intercepto y de la pendiente, se obtiene la l√≠nea de regresi√≥n de MCO.]

<br>

$$E(Y/X) = \hat{\beta_0} + \hat{\beta_1}{X}$$

$$\hat{Y} = \hat{\beta_0} + \hat{\beta_1}{X}$$

<br>
<br>

> - **El intercepto,** $\hat{\beta_0}$ es el valor predicho de Y cuando $X = 0$, aunque en algunos casos no tiene sentido hacer $X = 0$.

> - **La pendiente,** $\hat{\beta_1}$ es de primordial inter√©s, pues indica la cantidad en la que cambia $\hat{Y}$ cuando X se incrementa en una unidad.



---

name: propiedades
class: inverse, center, middle

# `r icon("database")`
# Propiedades algebraicas de los estimadores
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---


# MCO 

### Propiedades algebraicas de los estimadores


Las estimaciones de MCO y sus correspondientes estad√≠sticos tienen varias propiedades √∫tiles.

<br>

> 1Ô∏è‚É£ La suma, y por tanto el promedio muestral de los residuales de MCO, es cero. Matem√°ticamente,


$$\sum \hat{u} = 0$$


> 2Ô∏è‚É£ La covarianza muestral de los regresores y los residuales de MCO es cero.

$$Cov(x,u) = 0$$


### Demostrar lo anterior. 

.orange[Recuerde la f√≥rmula de la covarianza:] $cov(x,y) = E[(x - E(x))(y - E(y))]$


---


# MCO

### Propiedades algebraicas de los estimadores

$$\begin{align}
cov(u,x) &=& E[(u - E(u))(x - E(x))] \nonumber \\
&=& E[u (x - E(x)] \nonumber  \\
&=& E[ux - uE(x)] \nonumber  \\
&=& E(ux) - E(u)E(x) \nonumber \\
&=& 0 - 0E(x) \nonumber \\
&=& 0 \nonumber
\end{align}$$

o

$$\begin{align}
cov(u,x) &=& E(ux) - E(u)E(x) \nonumber \\
0 &=& E(ux) - 0E(x) \nonumber \\
cov(u,x) &=& E(ux) = 0 \nonumber
\end{align}$$


---

# MCO

### Propiedades algebraicas de los estimadores


> 3Ô∏è‚É£ El punto $(\bar{x},\bar{y})$ se encuentra siempre sobre la l√≠nea de regresi√≥n de MCO.

$$\hat{Y} = \hat{\beta_0} + \hat{\beta_1}{X}$$

$$\bar{Y} = \hat{\beta_0} + \hat{\beta_1}\bar{X}$$

.center[
<img src="img/promxy.jpg" width="25%"/>
]

---

name: supuestos
class: inverse, center, middle

# `r icon("database")`
# Supuestos modelo cl√°sico de regresi√≥n lineal
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal


El objetivo es no s√≥lo obtener $\hat{\beta_0}$ y $\hat{\beta_1}$ sino tambi√©n inferir los verdaderos ${\beta_0}$ y ${\beta_1}$; por ejemplo, si quisi√©ramos saber cu√°n cerca est√° $\hat{Y}$ de la verdadera $E(Y/X)$.


<br>

> üëâÔ∏è **Supuesto 1.** .orange[Modelo de regresi√≥n lineal]

<br>

El modelo de regresi√≥n es lineal en los par√°metros, aunque puede o no ser lineal en las variables.

### Ejemplo:

$$Y = \beta_0 + \beta_1{X} + u$$
$$Y = \beta_0 + \beta_1{X^2} + u$$

---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 2.** .orange[Valores fijos de X, o valores de X independientes del t√©rmino de error:]

<br>


Los valores que toma la regresora $X$ pueden considerarse fijos en muestras repetidas (el caso de la regresora fija), o haber sido muestreados junto con la variable dependiente $Y$ (el caso de la regresora estoc√°stica).

<br>

En el segundo caso se supone que la(s) variable(s) $X$ y el t√©rmino de error son independientes.

<br>

.font160[$$cov(x,u) = 0$$]


---


# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 2.** .orange[Valores fijos de X, o valores de X independientes del t√©rmino de error:]

<br>


## .green[De tal manera...]

* $X_i$ es **end√≥geno** si...

.font150[$$cov(u,x) \neq 0$$]

* $X_i$ es **ex√≥geno** si...

.font150[$$cov(u,x) = 0$$]

---

class: center, middle

# Si se garantiza la exogeneidad estricta los estimadores son insesgados y consistentes

---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 3.** .orange[El valor medio de la perturbaci√≥n ui es igual a cero]

<br>

Dado el valor de $X_i$, la media o el valor esperado del t√©rmino de perturbaci√≥n aleatoria $u_i$ es cero.

<br>

$$E(u/x) = 0$$


si, $X$ no es estoc√°stica (aleatoria),

<br>
$$E(u) = 0$$


---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 3.** .orange[El valor medio de la perturbaci√≥n ui es igual a cero]

<br>

**Es importante se√±alar:**

- El supuesto 3 implica que no hay sesgo de especificaci√≥n o error de especificaci√≥n en el modelo del an√°lisis emp√≠rico.

- Tambi√©n observe que si la media condicional de una variable aleatoria, dada otra variable aleatoria, es cero, la covarianza entre las dos variables es cero y, por tanto, las dos variables no est√°n correlacionadas. 

.center[
### **X y u no est√°n correlacionadas. --> .orange[Exogeneidad estricta]**
]



---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 4.** .orange[Homoscedasticidad o varianza constante de u]


La varianza del t√©rmino de error, o de perturbaci√≥n, es la misma sin importar el valor de $X$. Simb√≥licamente, tenemos que

$$\begin{align}
var(u/x) &=& E[u - E(u/x)]^2 \nonumber \\
&=& E[(u-E(u/x))(u-E(u/x))] \nonumber  \\
&=& E[u^2] - 2E(u)E(u/x) + (E(u/x))^2 \\
&=& E[u^2] - 2 (0)(0) + (0)^2 \\ 
&=& E[u^2] \\
&=& E[(y -\hat{y})^2] \\
&=& \sigma^2 \nonumber
\end{align}$$

Por el supuesto 3, $E(u|x) = 0$ es la esperanza del error condicionado a $x$. 


---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 5.** .orange[No hay autocorrelaci√≥n entre las perturbaciones]


<br>

Dados dos valores cualesquiera de $X$, $X_i$ y $X_j$ $(i \neq j )$, la correlaci√≥n entre dos $u_i$ y $u_j$ cualesquiera $(i \neq j )$ es cero. 

<br> 

En pocas palabras, estas observaciones se muestrean de manera independiente.

<br>

$$cov(u_i u_j / X_i X_j) = 0$$

---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 6.**  .orange[El n√∫mero de observaciones **n** debe ser mayor que el n√∫mero de par√°metros por estimar]

<br>

.center[
### Sucesivamente, el n√∫mero de observaciones n debe ser mayor que el n√∫mero de variables explicativas.
]


---

# MCO

### Supuestos modelo cl√°sico de regresi√≥n lineal

<br>

> üëâÔ∏è **Supuesto 7.**   .orange[La naturaleza de las variables X]

<br>

No todos los valores $X$ en una muestra determinada deben ser iguales. T√©cnicamente, $var(X)$ debe ser un n√∫mero positivo. 

Adem√°s, no puede haber valores at√≠picos de la variable $X$, es decir, valores muy grandes en relaci√≥n con el resto de las observaciones.


---


# Teorema de Gauss-Markov


### Un estimador $\hat{\beta_1}$ es el mejor estimador lineal insesgado (MELI) de $\beta_1$ si cumple lo siguiente:

<br>


.pull-left[

----

> - Es lineal, es decir, funci√≥n lineal de una variable aleatoria, como la variable dependiente Y en el modelo de regresi√≥n.


> - Es insesgado, es decir, su valor promedio o esperado, $E(\hat{\beta_1})$, es igual al valor verdadero, ${\beta_1}$


> - Tiene varianza m√≠nima dentro de la clase de todos los estimadores lineales insesgados; un estimador insesgado con varianza m√≠nima se conoce como estimador eficiente.


----

]


.pull-right[

.center[
### Gauss-Markov


<img src="img/markov.jpg" width="70%"/>
]
]

---

name: determinacion
class: inverse, center, middle

# `r icon("database")`
# Coeficiente de determinaci√≥n
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---


# Coeficiente de determinaci√≥n


Coeficiente de determinaci√≥n $r^2$: Proporci√≥n de la variabilidad de $Y$ que es posible explicar a trav√©s del modelo planteado, es decir, por la variaci√≥n de la variable dependiente $X$:

<br>

$$R^2 = r^2 \quad , \quad 0\leq R^2 \leq 1$$
<br>

> - Su c√°lculo es f√°cil, es el coeficiente de correlaci√≥n al cuadrado.
> - Para interpretar mejor el coeficiente de determinaci√≥n se debe convertir a porcentaje.


<br>

### ¬øCon cu√°nta exactitud predice la ecuaci√≥n de regresi√≥n a la variable $Y$ mediante la variable $X$?

> Si fuera posible hacer predicciones **perfectas** entonces $R^2 = 100\%$, esto significa que la variable independiente explica o representa toda la variaci√≥n de la variable dependiente

---

name: variacion
class: inverse, center, middle

# `r icon("database")`
# Fuentes de variaci√≥n
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---



# Fuentes de variaci√≥n

A medida que aumenta la fuerza de la relaci√≥n lineal entre dos variables, aumenta el coeficiente de correlaci√≥n y disminuye el error est√°ndar de estimaci√≥n, lo que indica que $S_{y.x}$ y $r$ est√°n inversamente relacionados.

<br>

.pull-left[

#### .orange[La variaci√≥n total se divide en dos componentes:]


----

#### 1. (SCR) El que se deriva de la regresi√≥n (a su vez, explicado por la variable independiente)

----

#### 2. (SCE) El error o residual, que es la variaci√≥n inexplicable

----

]

.pull-right[

<img src="img/Imagen8.jpg" width="90%"/>

]

---

# Fuentes de variaci√≥n

.center[
<img src="img/Imagen10.jpg" width="40%"/>
]

.pull-left[
Recuerde que el coeficiente de determinaci√≥n se define como el porcentaje de la variaci√≥n total (SCT) explicado por la ecuaci√≥n de regresi√≥n (SCR)... 

Entonces en t√©rminos de la varici√≥n total como puede escribirse el $R^2$ ?


$$R^2 =  \frac{SCR}{SCT} =  1 - \frac{SCE}{SCT}$$

]

.pull-right[

.orange[**Algunas f√≥rmulas √∫tiles:**]

- $SCT = S_{yy} = V(Y)$
- $SCR = r^2 SCT$
- $SCE = SCT - SCR$
- $R^2 = \frac{SCR}{SCT} = \frac{(S_{xy})^2}{S_{xx}S_{yy}}$

]

---


class: inverse, center, middle
background-color: #122140

.pull-left[

.center[
<br><br>

# Gracias!!!

<br>



### ¬øPreguntas?

<br>


```{r qr, echo=FALSE, fig.align="center", out.width="49%"}
knitr::include_graphics("img/qr-code.png")
```


]


]


.pull-right[

<br> 
<br> 
<img style="border-radius: 50%;" src="img/avatar.png"
width="150px"
/>

### [www.joaquibarandica.com](https://www.joaquibarandica.com)

`r icon("envelope")` orlando.joaqui@javerianacali.edu.co

<img src="img/Logo.jpg" width="120%">

]


<br><br><br>









